{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Harmony MaskFill service\n",
    "\n",
    "The Harmony MaskFill service takes gridded cloud-hosted input Earth Observation (EO) data granules, alongside a GeoJSON shape file, and masks all pixels outside the requested GeoJSON shape. These pixels are set to the fill value associated with each variable in question.\n",
    "\n",
    "This Jupyter notebook will demonstrate how data can be retrieved from the Harmony MaskFill service using the NASA `harmony-py` Python package.\n",
    "\n",
    "Note, that the MaskFill service is currently not used in isolation, but as part of a service chain, calling the Harmony OPeNDAP SubSetter (HOSS) first to crop the output to a minimally encompassing bounding box, before using MaskFill to mask all pixels inside that box, but outside the specified GeoJSON shape file.\n",
    "\n",
    "### Environment setup:\n",
    "\n",
    "This notebook assumes that it is being run in a local Python environment, configured using either `pyenv` or conda. Either can be used, but the dependencies will be installed via Pip. To install the required packages to run this notebook:\n",
    "\n",
    "```bash\n",
    "$ pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Note - your environment will require the [geos](https://trac.osgeo.org/geos/) package to be able to install all the dependencies for this notebook (particularly `cartopy`).\n",
    "\n",
    "`harmony-py` is available from [PyPI](https://pypi.org/project/harmony-py/). It can also be installed with Pip:\n",
    "\n",
    "```bash\n",
    "$ pip install harmony-py\n",
    "```\n",
    "\n",
    "### Notebook setup:\n",
    "\n",
    "`harmony-py` contains functionality to authenticate with Earthdata Login. It requires a `.netrc` (`_netrc` on Windows) file in your home directory:\n",
    "\n",
    "```\n",
    "machine uat.urs.earthdata.nasa.gov\n",
    "    login narmstrong\n",
    "    password ap0ll0\n",
    "```\n",
    "\n",
    "Make sure that this file is only readable by the current user or you will receive an error stating \"netrc access too permissive.\"\n",
    "\n",
    "```\n",
    "$ chmod 0600 ~/.netrc\n",
    "```\n",
    "\n",
    "Note that the Earthdata Login environment must match the Harmony environment containing the collection and service later in the notebook (e.g. UAT or production).\n",
    "\n",
    "#### Plotting functions\n",
    "\n",
    "The function below can be used to plot information from either the granule itself, or regarding the shape file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import contextily as ctx\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def plot_variable(variable_data, longitudes, latitudes, fill_value=None, title=None,\n",
    "                  colourbar_units=None):\n",
    "    \"\"\" This helper function will create a masked array, to remove fill values, then\n",
    "        it will load features using `cartopy` to display oceans, land, coastlines and\n",
    "        rivers on the output image. Then it will display a contour plot of the data,\n",
    "        before\n",
    "    \n",
    "        Plots variable against longitudes and latitudes in masked area on the world map.\n",
    "\n",
    "    \"\"\"\n",
    "    # Mask out fill values:\n",
    "    masked_variable = np.ma.masked_where(variable_data[:] == fill_value, variable_data)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, fontsize=20)\n",
    "\n",
    "    # Include basic features in contour plot:\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=0))\n",
    "    ax.add_feature(cfeature.OCEAN)\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.RIVERS)\n",
    "\n",
    "    # Plot masked data:\n",
    "    colour_scale = ax.contourf(longitudes, latitudes, masked_variable, levels=20)\n",
    "    \n",
    "    # Add colour bar for scaling\n",
    "    colour_bar = plt.colorbar(colour_scale, ax=ax, orientation='horizontal', pad=0.05)\n",
    "    if colourbar_units is not None:\n",
    "        colour_bar.set_label(colourbar_units, fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_shape_file(shape_file_path):\n",
    "    \"\"\" Plots a shape file from a GeoJSON input file against a background image\n",
    "        showing a map of the Earth.\n",
    "\n",
    "    \"\"\"\n",
    "    shape = gpd.read_file(shape_file_path).to_crs(epsg=3857)\n",
    "    plot = shape.plot(alpha=0.5, edgecolor='k', figsize=(8, 8))\n",
    "    ctx.add_basemap(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Information required by the Harmony request:\n",
    "\n",
    "The Harmony shape file subsetting request require a few pieces of information:\n",
    "\n",
    "* The concept ID of the data collection containing the granules to be processed. This has the format \"C1234567890-[PROVIDER]\".\n",
    "* The concept ID of the granule(s) being requested. This has the format \"G1234567890-[PROVIDER]\".\n",
    "* A shape file, saved as a GeoJSON file. (See below for more details on shape files).\n",
    "* Harmony endpoint URL.\n",
    "\n",
    "### Shape files:\n",
    "\n",
    "When making requests directly to Harmony, these shape files should contain one or more `Polygon` features. `MultiPolygon` features will not be accepted by the API, and should be split into a list of separate `Polygon` features. In addition all polygons should have their points ordered in an anticlockwise direction.\n",
    "\n",
    "## The test case:\n",
    "\n",
    "This test request will retrieve a granule from the [SMAP level 4, Net Carbon Ecosystem Exchange collection](https://nsidc.org/data/spl4cmdl) (SPL4CMDL). The SPL4CMDL collections shows estimates of Carbon Dioxide exchange, on the EASE-2 global (cylindrical) grid.\n",
    "\n",
    "The region of interest, as specified in the shape file, will be the Amazon river basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_shape_file('amazon_basin.geo.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `harmony-py` to make MaskFill requests\n",
    "\n",
    "We will use the SPL4CMDL collection and a sample granule, alongside the Amazon river basin GeoJSON shape, and make a Harmony request using the `harmony-py` package.\n",
    "\n",
    "As noted above, the `harmony-py` package can be installed from the Python Package Index using Pip:\n",
    "\n",
    "```bash\n",
    "$ pip install -U harmony-py\n",
    "```\n",
    "\n",
    "`harmony-py` creates a client, which requires Earthdata Login credientials. If a `.netrc` file exists in the home directory of your machine, the `harmony-py` client will attempt to retrieve Earthdata Login credentials from it.\n",
    "\n",
    "### The `harmony-py` `Client`:\n",
    "\n",
    "This class will handle the communication with the Harmony API, including authentication, as derived from a `.netrc` file. Requests are made by submitting a `Request` instance to Harmony using the `Client` instance. The `harmony-py` `Client` can be configured for any of the available Harmony environments, e.g. UAT or production.\n",
    "\n",
    "### Forming a `Request` instance:\n",
    "\n",
    "An instance of the `Request` object can be used to make requests to the Harmony API via the a harmony `Client` instance. To create a `Request` object, the collection must be specified. Additional arguments can be included. For example the concept IDs of granules or variables to be processed. Omitting granule IDs will result in Harmony trying to process all granules in a collection. Similarly, not specifying variables is the equivalent of requesting all variables in each granule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from harmony import Client, Collection, Request, Environment\n",
    "\n",
    "\n",
    "# Define the collection and granule concept IDs:\n",
    "collection_id = 'C1240150677-EEDTEST'\n",
    "granule_id = 'G1245558670-EEDTEST'\n",
    "\n",
    "# Create a client for the UAT environment:\n",
    "harmony_client = Client(env=Environment.UAT)\n",
    "\n",
    "# Specify the path to the locally saved GeoJSON shape file:\n",
    "shapefile = 'amazon_basin.geo.json'\n",
    "\n",
    "# Create a collection instance, using the concept ID:\n",
    "collection = Collection(id=collection_id)\n",
    "\n",
    "# Construct a request, ready to send to the Harmony API:\n",
    "request = Request(collection=collection, granule_id=[granule_id], shape='amazon_basin.geo.json')\n",
    "\n",
    "# Ensure the request is valid:\n",
    "print(f'Request is valid: {request.is_valid()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit requests and tracking progress\n",
    "\n",
    "Submitting a valid request to Harmony using the `Client` instance will return a job ID. This ID can be used to track the job status using in-built functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Submit a valid Harmony request via the UAT Harmony client.\n",
    "job_id = harmony_client.submit(request)\n",
    "\n",
    "# Show job progress\n",
    "print(f'\\nWaiting for the job {job_id} to finish')\n",
    "results = harmony_client.result_json(job_id, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data:\n",
    "\n",
    "The following cell will download all the processed output. The `Client.download_all` method will save local copies of each granule, and will return information about those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nDownloading results.')\n",
    "futures = harmony_client.download_all(job_id, overwrite=True)\n",
    "downloaded_files = [future.result() for future in futures]\n",
    "print(f'Downloaded files: {downloaded_files}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response JSON:\n",
    "\n",
    "If we're just interested in the json Harmony produces we can retrieve that also. This could be a useful way to retrieve the URLs of the processed data, without downloading those files until they are actually needed. It also provided information on the STAC catalogs for the output granules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "harmony_client.result_json(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the output:\n",
    "\n",
    "The cell below will plot the environmental constraint multiplier from the downloaded file retrieved by `harmony-py`. It should be identical to the output from using the Harmony API directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from h5py import File as H5File\n",
    "\n",
    "\n",
    "# Open the first output file:\n",
    "harmony_py_data = H5File(downloaded_files[0], 'r')\n",
    "\n",
    "# Plot the mean global net ecosystem exchange:\n",
    "plot_variable(harmony_py_data['/NEE/nee_mean'], harmony_py_data['/GEO/longitude'], harmony_py_data['/GEO/latitude'],\n",
    "              fill_value=-9999.0, title='Mean global daily 9km Net Ecosystem Exchange',\n",
    "              colourbar_units=r'$\\mathregular{g.cm^{-2}.day^{-1}}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: The rest of this notebook requires you to be running it in us-west-2.\n",
    "\n",
    "To do so follow tutorial 3 of the [NASA Earthdata Cloud Primer](https://earthdata.nasa.gov/learn/user-resources/webinars-and-tutorials/cloud-primer), but also open an inbound port (port 8888) in the security group settings of the EC2 instance, as detailed [here](https://medium.com/@alexjsanchez/python-3-notebooks-on-aws-ec2-in-15-mostly-easy-steps-2ec5e662c6c6). For more detailed instructions regarding running a Harmony Jupyter notebook in an EC2 instance, see [here](https://github.com/nasa/harmony/blob/main/docs/Harmony_20.3Demo.ipynb).\n",
    "\n",
    "### STAC catalog output\n",
    "\n",
    "Each successful Harmony request will return a [STAC](https://stacspec.org/) catalog. STAC allows for scripts to access information regarding assets, without first having to download and consume the full asset. With granules that can be hundreds of megabytes (or even several gigabytes) in size, this allows a user to inspect or even filter granules and optimise their workflow by only obtaining the data that are most useful to their analyses.\n",
    "\n",
    "The STAC catalog also includes the S3 location of each output file allowing for direct S3 access. Such information can be used by other cloud services, enabling in-place data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac import Catalog\n",
    "\n",
    "stac_catalog_url = harmony_client.stac_catalog_url(job_id)\n",
    "catalog = Catalog.from_file(stac_catalog_url)\n",
    "\n",
    "stac_s3_links = [asset.href for item in catalog.get_all_items() for asset in item.assets.values()]\n",
    "print(stac_s3_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata for each STAC item can be displayed to see information such as the bounding box, coordinates and start time or end time of the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "\n",
    "intake_catalog = intake.open_stac_catalog(stac_catalog_url, name='Harmony MaskFill')\n",
    "\n",
    "for stac_id, stac_item in intake_catalog.items():\n",
    "    print(f'{stac_id}\\n{stac_item.metadata}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud in-place analysis:\n",
    "\n",
    "Instead of requesting HTTPS URLs, which are the default, it is possible to request S3 URLs. These can be used to perform analysis in-place, or to retrieve the data directly from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from harmony import LinkType\n",
    "\n",
    "s3_output_urls = harmony_client.result_urls(job_id, link_type=LinkType.s3)\n",
    "s3_output_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing the data in-place:\n",
    "\n",
    "With the release of version 3.2, `h5py` is now able to use the ROS3 driver to read data from an object in S3. This does require some specific configuration of HDF5 and installation of `h5py`, as detailed [here](https://docs.h5py.org/en/stable/whatsnew/3.2.html?highlight=ros3#new-features). The next cell will generate some temporary AWS credential to enable access to the S3 bucket containing the results of the Harmony request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_credentials = harmony_client.aws_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting data directly from S3:\n",
    "\n",
    "The cell below shows how `h5py`, if configured with the ROS3 driver can allow for plotting of data as hosted in S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This cell will _only_ work if you follow the installation instructions here:\n",
    "# https://docs.h5py.org/en/stable/whatsnew/3.2.html?highlight=ros3#new-features\n",
    "# The ROS3 driver does not come automatically included in h5py == 3.2 as available\n",
    "# from PyPI.\n",
    "#\n",
    "from h5py import File as H5File\n",
    "\n",
    "\n",
    "# Open the output file stored in S3:\n",
    "s3_output_file = H5File(s3_output_urls[0], 'r', driver='ros3', aws_region='us-west-2',\n",
    "                        secret_id=aws_credentials['aws_access_key_id'],\n",
    "                        secret_key=aws_credentials['aws_secret_access_key'])\n",
    "\n",
    "# Plot the mean global net ecosystem exchange:\n",
    "plot_variable(s3_output_file['/NEE/nee_mean'], s3_output_file['/GEO/longitude'],\n",
    "              s3_output_file['/GEO/latitude'], fill_value=-9999.0,\n",
    "              title='Mean global daily 9km Net Ecosystem Exchange',\n",
    "              colourbar_units=r'$\\mathregular{g.cm^{-2}.day^{-1}}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading from S3:\n",
    "\n",
    "The following cell shows how the output files can be downloaded directly from S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from harmony import s3_components\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3', **aws_credentials)\n",
    "\n",
    "for s3_output_url in s3_output_urls:\n",
    "    s3_bucket, s3_object, file_name = s3_components(s3_output_url)\n",
    "\n",
    "    with open(file_name, 'wb') as file_handler:\n",
    "        s3.download_fileobj(s3_bucket, s3_object, file_handler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
